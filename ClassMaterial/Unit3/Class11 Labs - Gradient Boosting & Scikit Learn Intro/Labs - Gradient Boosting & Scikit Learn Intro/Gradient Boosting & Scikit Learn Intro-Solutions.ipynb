{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting & Scikit-Learn Intro\n",
    "\n",
    "This lab is designed to give everyone their first introduction to the Scikit-Learn API, and Gradient Boosting, one of the most powerful techniques in predictive modeling.\n",
    "\n",
    "During this lab you'll see if you can build a model, understand its working parts, and make improvements to your results!  \n",
    "\n",
    "The great thing about `Scikit Learn` is that its API is almost identical from one algorithm to another, so once you get the hang of how to use it, using different methods is fairly seamless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Load in the `iowa_housing.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('../../data/iowa_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Declare your `X` & `y` variables -- We'll be predicting price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "X = df.drop('SalePrice', axis=1)\n",
    "y = df['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Import `GradientBoostingRegressor` and initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbm = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5:** Call the `fit()` method on `X` & `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='deprecated',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6:** Check the score of your model using the `score()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9371367715410339"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your answer here\n",
    "gbm.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7:** Make a column that represents the predictions your model made for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "df['Predictions'] = gbm.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 8:** Take a look at the values returned from the `feature_importances_` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00083484, 0.00277247, 0.02783743, 0.56745495, 0.01227388,\n",
       "       0.04799766, 0.06092333, 0.08068937, 0.03701382, 0.08721593,\n",
       "       0.00864966, 0.00185042, 0.06448624])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your answer here\n",
    "gbm.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 9:** To make a bit more sense out of these, let's put these values into a more readable format.  \n",
    "\n",
    "Try making a 2 column dataframe using `X.columns` and the values from `feature_importances_` (they should correspond to one another)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Columns</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OverallQual</td>\n",
       "      <td>0.567455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GrLivArea.1</td>\n",
       "      <td>0.087216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1stFlrSF</td>\n",
       "      <td>0.080689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GarageCars</td>\n",
       "      <td>0.064486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GrLivArea</td>\n",
       "      <td>0.060923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>YearBuilt</td>\n",
       "      <td>0.047998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2ndFlrSF</td>\n",
       "      <td>0.037014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LotArea</td>\n",
       "      <td>0.027837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OverallCond</td>\n",
       "      <td>0.012274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FullBath</td>\n",
       "      <td>0.008650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSSubClass</td>\n",
       "      <td>0.002772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HalfBath</td>\n",
       "      <td>0.001850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id</td>\n",
       "      <td>0.000835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Columns  Importance\n",
       "3   OverallQual    0.567455\n",
       "9   GrLivArea.1    0.087216\n",
       "7      1stFlrSF    0.080689\n",
       "12   GarageCars    0.064486\n",
       "6     GrLivArea    0.060923\n",
       "5     YearBuilt    0.047998\n",
       "8      2ndFlrSF    0.037014\n",
       "2       LotArea    0.027837\n",
       "4   OverallCond    0.012274\n",
       "10     FullBath    0.008650\n",
       "1    MSSubClass    0.002772\n",
       "11     HalfBath    0.001850\n",
       "0            Id    0.000835"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your answer here\n",
    "feats = pd.DataFrame({\n",
    "    'Columns': X.columns,\n",
    "    'Importance': gbm.feature_importances_\n",
    "})\n",
    "\n",
    "# to make them more viewable\n",
    "feats.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 10:** Can you improve your results?  For now, toy around a little bit with a few different options for getting different results.  These could be any of the following:\n",
    "\n",
    " - changing the number of boosting rounds used via `n_estimators`\n",
    " - changing the learning rate\n",
    " - removing columns that have lower feature importance, or very low correlation with the target variable\n",
    " - combing associated columns into larger, more descriptive ones, like full bathrooms, total living area, etc\n",
    " \n",
    "**hint:** you can use the `set_params()` method to change the parameter values of a scikit-learn algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model score is: 0.9377636242979969\n"
     ]
    }
   ],
   "source": [
    "# your answer here\n",
    "# we'll talk about this in more detail, but here's a start\n",
    "# select the columns with feature importance of at least 1 %\n",
    "query = feats.Importance > .01\n",
    "cols_to_use = feats.loc[query, 'Columns'].tolist()\n",
    "# and fit and score our model with them -- a very modest improvement, but we'll take it\n",
    "print(f\"New model score is: {gbm.fit(X[cols_to_use], y).score(X[cols_to_use], y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9913900417055366, 0.1, 1000)\n"
     ]
    }
   ],
   "source": [
    "# to check for improvements we can make with parameters we'll go use a nested for loop\n",
    "rates = [.001, .01, .1]\n",
    "num_trees = [100, 500, 1000]\n",
    "mod_scores = []\n",
    "\n",
    "for rate in rates:\n",
    "    for tree in num_trees:\n",
    "        gbm.set_params(learning_rate=rate, n_estimators=tree)\n",
    "        score = gbm.fit(X[cols_to_use], y).score(X[cols_to_use], y)\n",
    "        mod_scores.append((score, rate, tree))\n",
    "        \n",
    "print(max(mod_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
